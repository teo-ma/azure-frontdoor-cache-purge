#!/usr/bin/env python3
"""
Azure Front Door ç¼“å­˜åˆ·æ–°éªŒè¯å·¥å…·

è¿™ä¸ªè„šæœ¬å¸®åŠ©æ‚¨éªŒè¯ç¼“å­˜åˆ·æ–°æ˜¯å¦çœŸæ­£ç”Ÿæ•ˆã€‚
"""

import requests
import time
from datetime import datetime
from typing import List, Dict

def test_cache_refresh(urls: List[str], test_iterations: int = 3) -> Dict:
    """
    æµ‹è¯•ç¼“å­˜åˆ·æ–°æ•ˆæœ
    
    Args:
        urls: è¦æµ‹è¯•çš„URLåˆ—è¡¨
        test_iterations: æµ‹è¯•æ¬¡æ•°
    
    Returns:
        æµ‹è¯•ç»“æœå­—å…¸
    """
    results = {}
    
    print("ğŸ§ª å¼€å§‹ç¼“å­˜åˆ·æ–°éªŒè¯æµ‹è¯•")
    print("=" * 50)
    
    for url in urls:
        print(f"\nğŸ” æµ‹è¯• URL: {url}")
        results[url] = []
        
        for i in range(test_iterations):
            try:
                print(f"  ç¬¬ {i+1} æ¬¡è¯·æ±‚...")
                
                # å‘èµ·HTTPè¯·æ±‚
                start_time = time.time()
                response = requests.get(url, timeout=10)
                response_time = time.time() - start_time
                
                # è·å–å“åº”å¤´ä¿¡æ¯
                headers_info = {
                    'status_code': response.status_code,
                    'response_time': round(response_time * 1000, 2),  # æ¯«ç§’
                    'timestamp': datetime.now().strftime('%H:%M:%S'),
                    'cache_control': response.headers.get('Cache-Control', 'N/A'),
                    'etag': response.headers.get('ETag', 'N/A'),
                    'last_modified': response.headers.get('Last-Modified', 'N/A'),
                    'x_cache': response.headers.get('X-Cache', 'N/A'),
                    'x_azure_ref': response.headers.get('X-Azure-Ref', 'N/A'),
                    'content_length': response.headers.get('Content-Length', 'N/A')
                }
                
                results[url].append(headers_info)
                
                print(f"    âœ… çŠ¶æ€: {headers_info['status_code']}, "
                      f"å“åº”æ—¶é—´: {headers_info['response_time']}ms, "
                      f"X-Cache: {headers_info['x_cache']}")
                
                # é—´éš”ä¸€æ®µæ—¶é—´
                if i < test_iterations - 1:
                    time.sleep(2)
                    
            except requests.RequestException as e:
                error_info = {
                    'error': str(e),
                    'timestamp': datetime.now().strftime('%H:%M:%S')
                }
                results[url].append(error_info)
                print(f"    âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
    
    return results

def analyze_results(results: Dict) -> None:
    """åˆ†ææµ‹è¯•ç»“æœ"""
    print("\n" + "=" * 50)
    print("ğŸ“Š ç¼“å­˜åˆ·æ–°éªŒè¯ç»“æœåˆ†æ")
    print("=" * 50)
    
    for url, tests in results.items():
        print(f"\nğŸŒ URL: {url}")
        print("-" * 40)
        
        # ç»Ÿè®¡æˆåŠŸçš„è¯·æ±‚
        successful_tests = [t for t in tests if 'status_code' in t]
        
        if not successful_tests:
            print("âŒ æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥äº†")
            continue
        
        # åˆ†æå“åº”æ—¶é—´å˜åŒ–
        response_times = [t['response_time'] for t in successful_tests]
        avg_response_time = sum(response_times) / len(response_times)
        
        print(f"âœ… æˆåŠŸè¯·æ±‚: {len(successful_tests)}/{len(tests)}")
        print(f"ğŸ“ˆ å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ms")
        
        # åˆ†æç¼“å­˜å¤´å˜åŒ–
        cache_headers = [t.get('x_cache', 'N/A') for t in successful_tests]
        unique_cache_states = set(cache_headers)
        
        print(f"ğŸ’¾ Cache çŠ¶æ€å˜åŒ–: {list(unique_cache_states)}")
        
        # åˆ†æ ETag å˜åŒ–
        etags = [t.get('etag', 'N/A') for t in successful_tests]
        unique_etags = set(etags)
        
        if len(unique_etags) > 1:
            print("ğŸ”„ æ£€æµ‹åˆ°å†…å®¹å˜åŒ– (ETagä¸åŒ)")
        else:
            print("ğŸ“Œ å†…å®¹æœªå˜åŒ– (ETagç›¸åŒ)")
        
        # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        print("\nè¯¦ç»†è¯·æ±‚ä¿¡æ¯:")
        for i, test in enumerate(successful_tests, 1):
            print(f"  {i}. {test['timestamp']} - "
                  f"çŠ¶æ€:{test['status_code']} - "
                  f"æ—¶é—´:{test['response_time']}ms - "
                  f"Cache:{test.get('x_cache', 'N/A')}")

def get_front_door_urls() -> List[str]:
    """è·å–è¦æµ‹è¯•çš„Front Door URLs"""
    print("ğŸ”— è¯·è¾“å…¥è¦æµ‹è¯•çš„ Front Door URLs")
    print("æç¤º: è¾“å…¥å®Œæ•´çš„URLï¼Œä¾‹å¦‚ https://your-site.azurefd.net/")
    print("è¾“å…¥ç©ºè¡Œç»“æŸ\n")
    
    urls = []
    while True:
        url = input(f"URL {len(urls)+1}: ").strip()
        if not url:
            break
        
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        
        urls.append(url)
    
    return urls

def main():
    """ä¸»å‡½æ•°"""
    print("Azure Front Door ç¼“å­˜åˆ·æ–°éªŒè¯å·¥å…·")
    print("=" * 50)
    print("è¿™ä¸ªå·¥å…·å¸®åŠ©æ‚¨éªŒè¯ç¼“å­˜åˆ·æ–°æ˜¯å¦ç”Ÿæ•ˆ")
    print("å»ºè®®åœ¨æ‰§è¡Œç¼“å­˜æ¸…é™¤æ“ä½œå‰åè¿è¡Œæ­¤å·¥å…·è¿›è¡Œå¯¹æ¯”\n")
    
    # è·å–æµ‹è¯•URLs
    urls = get_front_door_urls()
    
    if not urls:
        print("âŒ æ²¡æœ‰æä¾›æµ‹è¯•URL")
        return
    
    print(f"\nğŸ“‹ å°†æµ‹è¯•ä»¥ä¸‹URLs: {urls}")
    
    # è¯¢é—®æµ‹è¯•æ¬¡æ•°
    try:
        iterations = int(input("\nğŸ”¢ æµ‹è¯•æ¬¡æ•° (é»˜è®¤3æ¬¡): ") or "3")
    except ValueError:
        iterations = 3
    
    print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œ {iterations} æ¬¡æµ‹è¯•...")
    
    # æ‰§è¡Œæµ‹è¯•
    results = test_cache_refresh(urls, iterations)
    
    # åˆ†æç»“æœ
    analyze_results(results)
    
    print("\n" + "=" * 50)
    print("ğŸ’¡ éªŒè¯æç¤º:")
    print("1. å¦‚æœå“åº”æ—¶é—´æ˜æ˜¾å˜åŒ–ï¼Œå¯èƒ½è¡¨ç¤ºç¼“å­˜å·²åˆ·æ–°")
    print("2. X-Cache å¤´ä» HIT å˜ä¸º MISS è¡¨ç¤ºç¼“å­˜å·²æ¸…é™¤")
    print("3. ETag æˆ– Last-Modified å˜åŒ–è¡¨ç¤ºå†…å®¹å·²æ›´æ–°")
    print("4. å»ºè®®åœ¨ç¼“å­˜æ¸…é™¤å‰åå„è¿è¡Œä¸€æ¬¡æ­¤å·¥å…·è¿›è¡Œå¯¹æ¯”")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
